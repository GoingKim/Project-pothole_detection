{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bdcdcea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '../../data/'\n",
    "PREDICTION_THRES = 0.8\n",
    "EPOCHS = 10\n",
    "MIN_SIZE = 800\n",
    "BATCH_SIZE = 4\n",
    "DEBUG = False # to visualize the images before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "de564d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import  FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cdf4ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True,min_size=MIN_SIZE)\n",
    "    # one class is for pot holes, and the other is background\n",
    "    num_classes = 2\n",
    "    # get the input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace pre-trained head with our features head\n",
    "    # the head layer will classify the images based on our data input features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "617f0d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotHoleDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_ids = dataframe['path'].unique()\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "        records = self.df[self.df['path'] == image_id]\n",
    "        image = cv2.imread(self.image_dir+image_id, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        \n",
    "        # convert the boxes into x_min, y_min, x_max, y_max format\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        \n",
    "        # get the area of the bounding boxes\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "        # we have only one class\n",
    "        labels = torch.ones((records.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        # supposing that all instances are not crowd\n",
    "        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "        # apply the image transforms\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            \n",
    "            # convert the bounding boxes to PyTorch `FloatTensor`\n",
    "            target['boxes'] = torch.stack(tuple(map(torch.FloatTensor, \n",
    "                                                    zip(*sample['bboxes'])))).permute(1, 0)\n",
    "        return image, target, image_id\n",
    "    def __len__(self):\n",
    "        return self.image_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "02ef3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b42d7214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for the image transforms\n",
    "def train_transform():\n",
    "    return A.Compose([\n",
    "        A.Flip(0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "379e12f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4220"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the annotation CSV file\n",
    "train_df = pd.read_csv(\"../../data/df.csv\")\n",
    "len(train_df['path'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "be6899ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PotHoleDataset(train_df, ROOT_PATH, train_transform())\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fb06983e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the computation device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "18d0936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        images, targets, images_ids = data[0], data[1], data[2]\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 25 == 0:\n",
    "            print(f\"Iteration #{i} loss: {loss}\")\n",
    "    train_loss = running_loss/len(train_dataloader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "33796622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    torch.save(model.state_dict(), './fasterrcnn_resnet50_fpn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "34b2857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize():\n",
    "    \"\"\"\n",
    "    This function will only execute if `DEBUG` is `True` in \n",
    "    `config.py`.\n",
    "    \"\"\"\n",
    "    images, targets, image_ids = next(iter(train_data_loader))\n",
    "    images = list(image for image in images)\n",
    "    targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "    for i in range(1):\n",
    "        boxes = targets[i]['boxes'].cpu().numpy().astype(np.int32)\n",
    "        sample = images[i].permute(1,2,0).cpu().numpy()\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "        for box in boxes:\n",
    "            cv2.rectangle(sample,\n",
    "                        (box[0], box[1]),\n",
    "                        (box[2], box[3]),\n",
    "                        (220, 0, 0), 3)\n",
    "        ax.set_axis_off()\n",
    "        plt.imshow(sample)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "57fad89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d108f51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0 loss: 0.9971181750297546\n",
      "Iteration #25 loss: 0.2045029252767563\n",
      "Iteration #50 loss: 0.18742145597934723\n",
      "Iteration #75 loss: 0.5487701892852783\n",
      "Iteration #100 loss: 0.35096919536590576\n",
      "Iteration #125 loss: 0.25723928213119507\n",
      "Iteration #150 loss: 0.1721670925617218\n",
      "Iteration #175 loss: 0.2226804494857788\n",
      "Iteration #200 loss: 0.1561579704284668\n",
      "Iteration #225 loss: 0.4392942488193512\n",
      "Iteration #250 loss: 0.3433094918727875\n",
      "Iteration #275 loss: 0.3212968707084656\n",
      "Iteration #300 loss: 0.35688844323158264\n",
      "Iteration #325 loss: 0.29904186725616455\n",
      "Epoch #0 loss: 0.0819005481206945\n",
      "Took 5.881178259849548 minutes for epoch 0\n",
      "Iteration #0 loss: 0.15747389197349548\n",
      "Iteration #25 loss: 0.0897674411535263\n",
      "Iteration #50 loss: 0.12598007917404175\n",
      "Iteration #75 loss: 0.40307003259658813\n",
      "Iteration #100 loss: 0.1770906299352646\n",
      "Iteration #125 loss: 0.1774076372385025\n",
      "Iteration #150 loss: 0.1497049778699875\n",
      "Iteration #175 loss: 0.1410556435585022\n",
      "Iteration #200 loss: 0.12318956851959229\n",
      "Iteration #225 loss: 0.3880457878112793\n",
      "Iteration #250 loss: 0.2881997525691986\n",
      "Iteration #275 loss: 0.31800875067710876\n",
      "Iteration #300 loss: 0.30861449241638184\n",
      "Iteration #325 loss: 0.19368942081928253\n",
      "Epoch #1 loss: 0.06750511940036501\n",
      "Took 5.945210369427999 minutes for epoch 1\n",
      "Iteration #0 loss: 0.10828804224729538\n",
      "Iteration #25 loss: 0.0929040014743805\n",
      "Iteration #50 loss: 0.0823439359664917\n",
      "Iteration #75 loss: 0.32355254888534546\n",
      "Iteration #100 loss: 0.18019559979438782\n",
      "Iteration #125 loss: 0.16835752129554749\n",
      "Iteration #150 loss: 0.13869011402130127\n",
      "Iteration #175 loss: 0.13708966970443726\n",
      "Iteration #200 loss: 0.09548391401767731\n",
      "Iteration #225 loss: 0.34815463423728943\n",
      "Iteration #250 loss: 0.2719042897224426\n",
      "Iteration #275 loss: 0.2519902288913727\n",
      "Iteration #300 loss: 0.25063425302505493\n",
      "Iteration #325 loss: 0.20615100860595703\n",
      "Epoch #2 loss: 0.06128345798701048\n",
      "Took 5.874431892236074 minutes for epoch 2\n",
      "Iteration #0 loss: 0.11958447843790054\n",
      "Iteration #25 loss: 0.09377284348011017\n",
      "Iteration #50 loss: 0.11320538818836212\n",
      "Iteration #75 loss: 0.32625049352645874\n",
      "Iteration #100 loss: 0.13383309543132782\n",
      "Iteration #125 loss: 0.1187288910150528\n",
      "Iteration #150 loss: 0.11672138422727585\n",
      "Iteration #175 loss: 0.1022457405924797\n",
      "Iteration #200 loss: 0.09920445829629898\n",
      "Iteration #225 loss: 0.3609955608844757\n",
      "Iteration #250 loss: 0.20915380120277405\n",
      "Iteration #275 loss: 0.23533371090888977\n",
      "Iteration #300 loss: 0.262113094329834\n",
      "Iteration #325 loss: 0.22675228118896484\n",
      "Epoch #3 loss: 0.059352820701897145\n",
      "Took 5.906633639335633 minutes for epoch 3\n",
      "Iteration #0 loss: 0.12678390741348267\n",
      "Iteration #25 loss: 0.08322129398584366\n",
      "Iteration #50 loss: 0.09724666178226471\n",
      "Iteration #75 loss: 0.3133368194103241\n",
      "Iteration #100 loss: 0.15408337116241455\n",
      "Iteration #125 loss: 0.12159749865531921\n",
      "Iteration #150 loss: 0.1192956417798996\n",
      "Iteration #175 loss: 0.12685663998126984\n",
      "Iteration #200 loss: 0.09793360531330109\n",
      "Iteration #225 loss: 0.332594633102417\n",
      "Iteration #250 loss: 0.22280314564704895\n",
      "Iteration #275 loss: 0.25745823979377747\n",
      "Iteration #300 loss: 0.2488119751214981\n",
      "Iteration #325 loss: 0.21068356931209564\n",
      "Epoch #4 loss: 0.05758836604920881\n",
      "Took 5.917156175772349 minutes for epoch 4\n",
      "Iteration #0 loss: 0.14916139841079712\n",
      "Iteration #25 loss: 0.0931122899055481\n",
      "Iteration #50 loss: 0.10375197231769562\n",
      "Iteration #75 loss: 0.2836515009403229\n",
      "Iteration #100 loss: 0.14477604627609253\n",
      "Iteration #125 loss: 0.12312953174114227\n",
      "Iteration #150 loss: 0.10176004469394684\n",
      "Iteration #175 loss: 0.12461701035499573\n",
      "Iteration #200 loss: 0.11948816478252411\n",
      "Iteration #225 loss: 0.32223817706108093\n",
      "Iteration #250 loss: 0.2148423045873642\n",
      "Iteration #275 loss: 0.23687058687210083\n",
      "Iteration #300 loss: 0.23115131258964539\n",
      "Iteration #325 loss: 0.1753956824541092\n",
      "Epoch #5 loss: 0.05754289037414959\n",
      "Took 5.954044437408447 minutes for epoch 5\n",
      "Iteration #0 loss: 0.11022834479808807\n",
      "Iteration #25 loss: 0.09602344781160355\n",
      "Iteration #50 loss: 0.09673187136650085\n",
      "Iteration #75 loss: 0.22746145725250244\n",
      "Iteration #100 loss: 0.1575331836938858\n",
      "Iteration #125 loss: 0.1392861008644104\n",
      "Iteration #150 loss: 0.09891554713249207\n",
      "Iteration #175 loss: 0.10783730447292328\n",
      "Iteration #200 loss: 0.08447135984897614\n",
      "Iteration #225 loss: 0.3538321852684021\n",
      "Iteration #250 loss: 0.20392048358917236\n",
      "Iteration #275 loss: 0.20182891190052032\n",
      "Iteration #300 loss: 0.2516721487045288\n",
      "Iteration #325 loss: 0.19868934154510498\n",
      "Epoch #6 loss: 0.056019423183585916\n",
      "Took 5.878660007317861 minutes for epoch 6\n",
      "Iteration #0 loss: 0.1228872612118721\n",
      "Iteration #25 loss: 0.08611565828323364\n",
      "Iteration #50 loss: 0.10885259509086609\n",
      "Iteration #75 loss: 0.25705641508102417\n",
      "Iteration #100 loss: 0.12242748588323593\n",
      "Iteration #125 loss: 0.15384894609451294\n",
      "Iteration #150 loss: 0.1372961550951004\n",
      "Iteration #175 loss: 0.10444847494363785\n",
      "Iteration #200 loss: 0.08298404514789581\n",
      "Iteration #225 loss: 0.2864753007888794\n",
      "Iteration #250 loss: 0.2391287237405777\n",
      "Iteration #275 loss: 0.17387790977954865\n",
      "Iteration #300 loss: 0.2153540551662445\n",
      "Iteration #325 loss: 0.17322681844234467\n",
      "Epoch #7 loss: 0.05428214389830828\n",
      "Took 5.878783484299977 minutes for epoch 7\n",
      "Iteration #0 loss: 0.13558503985404968\n",
      "Iteration #25 loss: 0.09295926243066788\n",
      "Iteration #50 loss: 0.07640912383794785\n",
      "Iteration #75 loss: 0.25210338830947876\n",
      "Iteration #100 loss: 0.10996934771537781\n",
      "Iteration #125 loss: 0.1119249016046524\n",
      "Iteration #150 loss: 0.10024736821651459\n",
      "Iteration #175 loss: 0.09654968976974487\n",
      "Iteration #200 loss: 0.07238028943538666\n",
      "Iteration #225 loss: 0.2677534222602844\n",
      "Iteration #250 loss: 0.22235633432865143\n",
      "Iteration #275 loss: 0.2577865719795227\n",
      "Iteration #300 loss: 0.24122188985347748\n",
      "Iteration #325 loss: 0.1880427449941635\n",
      "Epoch #8 loss: 0.054768750305686675\n",
      "Took 5.898337137699127 minutes for epoch 8\n",
      "Iteration #0 loss: 0.1347668617963791\n",
      "Iteration #25 loss: 0.09539029002189636\n",
      "Iteration #50 loss: 0.09080666303634644\n",
      "Iteration #75 loss: 0.22887028753757477\n",
      "Iteration #100 loss: 0.11456090956926346\n",
      "Iteration #125 loss: 0.1185230016708374\n",
      "Iteration #150 loss: 0.1307915598154068\n",
      "Iteration #175 loss: 0.09477203339338303\n",
      "Iteration #200 loss: 0.09591063857078552\n",
      "Iteration #225 loss: 0.29705750942230225\n",
      "Iteration #250 loss: 0.2562115788459778\n",
      "Iteration #275 loss: 0.20877793431282043\n",
      "Iteration #300 loss: 0.22042392194271088\n",
      "Iteration #325 loss: 0.16047510504722595\n",
      "Epoch #9 loss: 0.05427845296050821\n",
      "Took 5.929104642073313 minutes for epoch 9\n"
     ]
    }
   ],
   "source": [
    "num_epochs = EPOCHS\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    train_loss = train(train_data_loader)\n",
    "    print(f\"Epoch #{epoch} loss: {train_loss}\")   \n",
    "    end = time.time()\n",
    "    print(f\"Took {(end - start) / 60} minutes for epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1637bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8a5c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299412e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05feceda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17e821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc15441e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b2641c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d45cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skku]",
   "language": "python",
   "name": "conda-env-skku-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
