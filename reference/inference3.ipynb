{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has version issue\n",
    "# If you don't downgrade torch and torchvision, you can get runtime cuda error.\n",
    "# ex> \"runtimeerror: gather_out_cuda(): expected dtype int64 for index\"\n",
    "\n",
    "# !pip install torch==1.5.0\n",
    "# !pip install torchvision==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/kerrykim/PycharmProjects/3.road_obstacle_detection/wbf',\n",
       " '/home/kerrykim/PycharmProjects/3.road_obstacle_detection/omegaconf',\n",
       " '/home/kerrykim/PycharmProjects/3.road_obstacle_detection/effdet',\n",
       " '/home/kerrykim/PycharmProjects/3.road_obstacle_detection/wbf',\n",
       " '/home/kerrykim/PycharmProjects/3.road_obstacle_detection/omegaconf',\n",
       " '/home/kerrykim/PycharmProjects/3.road_obstacle_detection/effdet',\n",
       " '/home/kerrykim/Jupyter/skku',\n",
       " '/home/kerrykim/anaconda3/envs/skku/lib/python39.zip',\n",
       " '/home/kerrykim/anaconda3/envs/skku/lib/python3.9',\n",
       " '/home/kerrykim/anaconda3/envs/skku/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/home/kerrykim/anaconda3/envs/skku/lib/python3.9/site-packages',\n",
       " '/home/kerrykim/anaconda3/envs/skku/lib/python3.9/site-packages/IPython/extensions',\n",
       " '/home/kerrykim/.ipython']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'effdet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26754/1119081523.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meffdet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_efficientdet_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEfficientDet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDetBenchEval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meffdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficientdet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHeadNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble_boxes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'effdet'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/kerrykim/PycharmProjects/3.road_obstacle_detection/effdet')\n",
    "sys.path.insert(0, '/home/kerrykim/PycharmProjects/3.road_obstacle_detection/omegaconf')\n",
    "sys.path.insert(0, '/home/kerrykim/PycharmProjects/3.road_obstacle_detection/wbf')\n",
    "                \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchEval\n",
    "from effdet.efficientdet import HeadNet\n",
    "from wbf.ensemble_boxes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configurations\n",
    "class CFG:\n",
    "    mode = 'test'\n",
    "    seed = 42\n",
    "    print_freq = 30\n",
    "\n",
    "    n_class = 5\n",
    "\n",
    "    img_x = 512\n",
    "    img_y = 512\n",
    "\n",
    "    num_fold = 5\n",
    "    num_epoch = 50\n",
    "    batch_size = 2\n",
    "    num_workers = 2    # decide how many data upload to dataset for a batch\n",
    "                       # if n_workers 2, dataloader works twice for a batch.\n",
    "                       # It has impact for cuda memory too\n",
    "\n",
    "    lr = 0.0002\n",
    "\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "\n",
    "    data_dir = './data_origin/test'\n",
    "    ckpt_dir = './checkpoint/final_f1_ep3_bt2_date05.03-15:06.pth'\n",
    "    result_dir = './result'\n",
    "    log_dir = './log'\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        lst_input = os.listdir(self.data_dir)\n",
    "        self.lst_input = lst_input\n",
    "        self.image_id = [image_id.split('/')[-1][:-4] for image_id in lst_input]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lst_input)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.image_id[index]\n",
    "        image = cv2.imread(os.path.join(self.data_dir, self.lst_input[index]), cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        if self.transform:\n",
    "            sample = {'image' : image}\n",
    "            sample = self.transform(**sample)    # 이때까지 해왔던 입력방식은 cv2 이미지를 직접 입력, 여기선 numpy 로 입력\n",
    "            image = sample['image']\n",
    "\n",
    "        return image, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(ckpt_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "\n",
    "    config.num_classes = 1\n",
    "    config.image_size=512\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    # net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    # net.load_state_dict(checkpoint, strict=False) # strict=False 해주니까 된다.\n",
    "    net.load_state_dict(checkpoint)\n",
    "    \n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    net = (DetBenchEval(net, config)).to(device)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test():\n",
    "    return A.Compose([A.Resize(height=512, width=512, p=1.0), ToTensorV2(p=1.0)], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(loader_test, net, score_threshold=0.22):\n",
    "    net.eval()\n",
    "    pred = []\n",
    "\n",
    "    ##\n",
    "    for batch, (images, image_ids) in enumerate(loader_test, 1):\n",
    "        images = torch.stack(images)\n",
    "        images = images.to(device).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            det = net(images, torch.tensor([1]*images.shape[0]).float().cuda())\n",
    "            output = []\n",
    "            for i in range(images.shape[0]):\n",
    "                boxes = det[i].detach().cpu().numpy()[:,:4]\n",
    "                scores = det[i].detach().cpu().numpy()[:,4]\n",
    "                indexes = np.where(scores > score_threshold)[0]\n",
    "                boxes = boxes[indexes]\n",
    "                boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "                boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "                output.append({\n",
    "                    'boxes': boxes[indexes],\n",
    "                    'scores': scores[indexes],\n",
    "                })\n",
    "\n",
    "            output = [output]\n",
    "\n",
    "        for i, image in enumerate(images):\n",
    "            boxes, scores, labels = run_wbf(output, image_index=i)\n",
    "            boxes = (boxes * 2).astype(np.int32).clip(min=0, max=1023)\n",
    "            image_id = image_ids[i]\n",
    "\n",
    "            boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "\n",
    "            tmp = {'image_id': image_id, 'PredictionString': format_prediction_string(boxes, scores)}\n",
    "\n",
    "            pred.append(tmp)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wbf(predictions, image_index, image_size=512, iou_thr=0.44, skip_box_thr=0.43, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prediction_string(boxes, scores):\n",
    "    pred_strings = []\n",
    "    for j in zip(scores, boxes):\n",
    "        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n",
    "    return \" \".join(pred_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    dataset_test = Dataset(data_dir=CFG.data_dir, transform=transform_test())\n",
    "    loader_test = DataLoader(dataset_test, batch_size=CFG.batch_size, shuffle=False, num_workers=8, drop_last=False, collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "    net = load_net(CFG.ckpt_dir)\n",
    "    pred = test_one_epoch(loader_test, net)\n",
    "\n",
    "    submission = pd.DataFrame(pred, columns=['image_id', 'PredictionString'])\n",
    "    submission.to_csv('submission.csv',index=False)\n",
    "    # submission.to_csv(os.path.join(CFG.result_dir, 'submission.csv'))\n",
    "    \n",
    "    return submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "if __name__ == \"__main__\":\n",
    "    if CFG.mode == \"test\":\n",
    "        submission = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skku]",
   "language": "python",
   "name": "conda-env-skku-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
