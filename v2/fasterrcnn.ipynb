{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde42a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = './Positive_data'\n",
    "TEST_PATH = './test'\n",
    "PREDICTION_THRES = 0.8\n",
    "EPOCHS = 5\n",
    "MIN_SIZE = 800\n",
    "BATCH_SIZE = 4\n",
    "DEBUG = False # to visualize the images before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0303117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import  FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b527e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True,min_size=MIN_SIZE)\n",
    "    # one class is for pot holes, and the other is background\n",
    "    num_classes = 2\n",
    "    # get the input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace pre-trained head with our features head\n",
    "    # the head layer will classify the images based on our data input features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba821969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotHoleDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "        self.image_ids = dataframe['image_id'].unique()\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "        records = self.df[self.df['image_id'] == image_id]\n",
    "        image = cv2.imread(f\"{self.image_dir}/{image_id}.JPG\", cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "    \n",
    "        # convert the boxes into x_min, y_min, x_max, y_max format\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        \n",
    "        # get the area of the bounding boxes\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        area = torch.as_tensor(area, dtype=torch.float32)\n",
    "        # we have only one class\n",
    "        labels = torch.ones((records.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        # supposing that all instances are not crowd\n",
    "        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "        # apply the image transforms\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': target['boxes'],\n",
    "                'labels': labels\n",
    "            }\n",
    "            sample = self.transforms(**sample)\n",
    "            image = sample['image']\n",
    "            \n",
    "            # convert the bounding boxes to PyTorch `FloatTensor`\n",
    "            target['boxes'] = torch.stack(tuple(map(torch.FloatTensor, \n",
    "                                                    zip(*sample['bboxes'])))).permute(1, 0)\n",
    "        return image, target, image_id\n",
    "    def __len__(self):\n",
    "        return self.image_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27294797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    This function helps when we have different number of object instances\n",
    "    in the batches in the dataset.\n",
    "    \"\"\"\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7292f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for the image transforms\n",
    "def train_transform():\n",
    "    return A.Compose([\n",
    "        A.Flip(0.5),\n",
    "        # A.RandomRotate90(0.5),\n",
    "        # A.MotionBlur(p=0.2),\n",
    "        # A.MedianBlur(blur_limit=3, p=0.1),\n",
    "        # A.Blur(blur_limit=3, p=0.1),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "734b26ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9089/579785536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mDIR_INPUT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mROOT_PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# read the annotation CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./_df.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total number of image IDs (objects) in dataframe: {len(train_df)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/skku/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/skku/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/skku/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/skku/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/skku/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/skku/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/skku/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/skku/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './_df.csv'"
     ]
    }
   ],
   "source": [
    "# path to the input root directory\n",
    "DIR_INPUT = ROOT_PATH\n",
    "# read the annotation CSV file\n",
    "train_df = pd.read_csv(\"./_df.csv\")\n",
    "print(train_df.head())\n",
    "print(f\"Total number of image IDs (objects) in dataframe: {len(train_df)}\")\n",
    "# get all the image paths as list\n",
    "image_paths = glob.glob(f\"{DIR_INPUT}/*.JPG\")\n",
    "image_names = []\n",
    "for image_path in image_paths:\n",
    "    image_names.append(image_path.split(os.path.sep)[-1].split('.')[0])\n",
    "print(f\"Total number of training images in folder: {len(image_names)}\")\n",
    "image_ids = train_df['image_id'].unique()\n",
    "print(f\"Total number of unique train images IDs in dataframe: {len(image_ids)}\")\n",
    "# number of images that we want to train out of all the unique images\n",
    "train_ids = image_names[:] # use all the images for training\n",
    "train_df = train_df[train_df['image_id'].isin(train_ids)]\n",
    "print(f\"Number of image IDs (objects) training on: {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d7e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PotHoleDataset(train_df, DIR_INPUT, train_transform())\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a536d05c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the computation device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        images, targets, images_ids = data[0], data[1], data[2]\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss for loss in loss_dict.values())\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 25 == 0:\n",
    "            print(f\"Iteration #{i} loss: {loss}\")\n",
    "    train_loss = running_loss/len(train_dataloader.dataset)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    torch.save(model.state_dict(), 'checkpoints/fasterrcnn_resnet50_fpn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize():\n",
    "    \"\"\"\n",
    "    This function will only execute if `DEBUG` is `True` in \n",
    "    `config.py`.\n",
    "    \"\"\"\n",
    "    images, targets, image_ids = next(iter(train_data_loader))\n",
    "    images = list(image for image in images)\n",
    "    targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "    for i in range(1):\n",
    "        boxes = targets[i]['boxes'].cpu().numpy().astype(np.int32)\n",
    "        sample = images[i].permute(1,2,0).cpu().numpy()\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "        for box in boxes:\n",
    "            cv2.rectangle(sample,\n",
    "                        (box[0], box[1]),\n",
    "                        (box[2], box[3]),\n",
    "                        (220, 0, 0), 3)\n",
    "        ax.set_axis_off()\n",
    "        plt.imshow(sample)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = EPOCHS\n",
    "# for epoch in range(num_epochs):\n",
    "#     start = time.time()\n",
    "#     train_loss = train(train_data_loader)\n",
    "# #     print(f\"Epoch #{epoch} loss: {train_loss}\")   \n",
    "#     end = time.time()\n",
    "#     print(f\"Took {(end - start) / 60} minutes for epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e4053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af64a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "from model import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43da99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the computation device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# load the model and the trained weights\n",
    "model = model().to(device)\n",
    "model.load_state_dict(torch.load('./fasterrcnn_resnet50_fpn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d9dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TEST = config.TEST_PATH\n",
    "test_images = os.listdir(DIR_TEST)\n",
    "print(f\"Validation instances: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_threshold = config.PREDICTION_THRES\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, image in tqdm(enumerate(test_images), total=len(test_images)):\n",
    "        orig_image = cv2.imread(f\"{DIR_TEST}/{test_images[i]}\", cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        # make the pixel range between 0 and 1\n",
    "        image /= 255.0\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float)\n",
    "        image = torch.tensor(image, dtype=torch.float).cuda()\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "        cpu_device = torch.device(\"cpu\")\n",
    "        outputs = model(image)\n",
    "        \n",
    "        outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]\n",
    "        if len(outputs[0]['boxes']) != 0:\n",
    "            for counter in range(len(outputs[0]['boxes'])):\n",
    "                boxes = outputs[0]['boxes'].data.numpy()\n",
    "                scores = outputs[0]['scores'].data.numpy()\n",
    "                boxes = boxes[scores >= detection_threshold].astype(np.int32)\n",
    "                draw_boxes = boxes.copy()\n",
    "                \n",
    "            for box in draw_boxes:\n",
    "                cv2.rectangle(orig_image,\n",
    "                            (int(box[0]), int(box[1])),\n",
    "                            (int(box[2]), int(box[3])),\n",
    "                            (0, 0, 255), 3)\n",
    "                cv2.putText(orig_image, 'PotHole', \n",
    "                            (int(box[0]), int(box[1]-5)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), \n",
    "                            2, lineType=cv2.LINE_AA)\n",
    "            cv2.imwrite(f\"test_predictions/{test_images[i]}\", orig_image,)\n",
    "print('TEST PREDICTIONS COMPLETE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10ed26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c51481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c23df90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab82ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3bd4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75d0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808bfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skku]",
   "language": "python",
   "name": "conda-env-skku-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
